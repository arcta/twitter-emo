{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streaming Twitter with Apache Spark 2\n",
    "[Using Kafka Example](https://github.com/cjdev/kafka-rx/tree/master/examples/twitter-stream/src/main/scala)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Configuration\n",
    "( Expected environment variables TWITTER_&lt;PROP&gt; set. )\n",
    "\n",
    "Twitter Authentication:\n",
    "<pre>\n",
    "twitter4j.oauth.consumerKey: TWITTER_CONSUMER_KEY\n",
    "twitter4j.oauth.consumerSecret: TWITTER_CONSUMER_SECRET\n",
    "twitter4j.oauth.accessToken: TWITTER_ACCESS_TOKEN\n",
    "twitter4j.oauth.accessTokenSecret: TWITTER_ACCESS_TOKEN_SECRET\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mjava.util.regex.Pattern\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.util.regex.Matcher\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mscala.util.Properties\n",
       "\n",
       "\n",
       "\u001b[39m\n",
       "defined \u001b[32mobject\u001b[39m \u001b[36mConf\u001b[39m"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import java.util.regex.Pattern\n",
    "import java.util.regex.Matcher\n",
    "import scala.util.Properties\n",
    "\n",
    "\n",
    "object Conf {\n",
    "    /** Configures Twitter API credentials using environment variables */\n",
    "    def setupTwitter() = {\n",
    "        val props = List(\"consumer_Key\", \"consumer_Secret\", \"access_Token\", \"access_Token_Secret\")\n",
    "        for (prop <- props) {\n",
    "            val local = \"TWITTER_\" + prop.toUpperCase\n",
    "            val conf = Properties.envOrElse(local, \"\")\n",
    "            if (conf != \"\") {\n",
    "                val name = prop.filterNot( _ == '_' )\n",
    "                System.setProperty(\"twitter4j.oauth.\" + name, conf)\n",
    "                println(\"Set Twitter auth.\" + name)\n",
    "            } else {\n",
    "                println(\"Missing Twitter credentials (env): \" + local)\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Twitter credentials (env): TWITTER_CONSUMER_KEY\n",
      "Missing Twitter credentials (env): TWITTER_CONSUMER_SECRET\n",
      "Set Twitter auth.accessToken\n",
      "Set Twitter auth.accessTokenSecret\n"
     ]
    }
   ],
   "source": [
    "Conf.setupTwitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                   \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                            \n",
       "\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.streaming._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.streaming.StreamingContext._\u001b[39m"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`org.apache.spark::spark-core:2.2.0`\n",
    "import $ivy.`org.apache.spark:spark-streaming_2.11:2.2.0`\n",
    "\n",
    "import org.apache.spark._\n",
    "import org.apache.spark.streaming._\n",
    "import org.apache.spark.streaming.StreamingContext._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import $ivy.`org.jupyter-scala::spark:0.4.2`\n",
    "\n",
    "#import jupyter.spark.session._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run:\n",
    "<pre>\n",
    "cd sbt\n",
    "sbt assembly\n",
    "cd target/scala-2.11\n",
    "spark-submit --master local[*] TwitterDataExplorer-assembly-0.1.0-SNAPSHOT.jar\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "/** Simple application to listen to a stream of Tweets */\n",
    "object TwitterDataExplorer {\n",
    "    /** Log error messages only */\n",
    "    def setupLogging() = {\n",
    "        import org.apache.log4j.{ Level, Logger }\n",
    "        val rootLogger = Logger.getRootLogger()\n",
    "        rootLogger.setLevel(Level.ERROR)\n",
    "    }\n",
    "\n",
    "    /** Configures Twitter API credentials using environment variables */\n",
    "    def setupTwitter() = {\n",
    "        val props = List(\"consumer_Key\", \"consumer_Secret\", \"access_Token\", \"access_Token_Secret\")\n",
    "        for (prop <- props) {\n",
    "            val local = \"TWITTER_\" + prop.toUpperCase\n",
    "            val conf = Properties.envOrElse(local, \"\")\n",
    "            if (conf != \"\") {\n",
    "                val name = prop.filterNot( _ == '_' )\n",
    "                System.setProperty(\"twitter4j.oauth.\" + name, conf)\n",
    "                println(\"Set Twitter auth.\" + name)\n",
    "            } else {\n",
    "                println(\"Missing Twitter credentials (env): \" + local)\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    /** Our main function where the action happens */\n",
    "    def main(args: Array[String]) {\n",
    "\n",
    "        setupLogging()\n",
    "        setupTwitter()\n",
    "\n",
    "        // Set up a Spark streaming context named \"PrintTweets\" 1sec batches of data\n",
    "        val conf = new SparkConf().setAppName(\"TwitterDataExplorer\")\n",
    "        val ssc = new StreamingContext(conf, Seconds(1))\n",
    "\n",
    "        // Create a DStream from Twitter using our streaming context\n",
    "        val tweets = TwitterUtils.createStream(ssc, None)\n",
    "        // Extract the text of each status update into RDD's\n",
    "        val statuses = tweets.map(status => status.getText())\n",
    "\n",
    "        // Print out the first ten\n",
    "        //statuses.print()\n",
    "\n",
    "        // Keep count of how many Tweets we've received\n",
    "        var total: Long = 0\n",
    "\n",
    "        statuses.foreachRDD((rdd, time) => {\n",
    "            // Don't bother with empty batches\n",
    "            if (rdd.count() > 0) {\n",
    "                // Combine each partition's results into a single RDD:\n",
    "                val repartitionedRDD = rdd.repartition(1).cache()\n",
    "                repartitionedRDD.saveAsTextFile(\"tweets-\" + time.milliseconds.toString)\n",
    "                // Stop once we've collected 1000 tweets.\n",
    "                total += repartitionedRDD.count()\n",
    "                println(\"Tweet count: \" + total)\n",
    "                if (total > 1000) {\n",
    "                    System.exit(0)\n",
    "                }\n",
    "            }\n",
    "        })\n",
    "\n",
    "        // Map to tweet character lengths\n",
    "        val lengths = statuses.map(status => status.length())\n",
    "\n",
    "        // As we could have multiple processes adding into these running totals\n",
    "        // Java's AtomicLong class to make sure these counters are thread-safe\n",
    "        var totalTweets = new AtomicLong(0)\n",
    "        var totalChars = new AtomicLong(0)\n",
    "\n",
    "        lengths.foreachRDD((rdd, time) => {\n",
    "            val count = rdd.count()\n",
    "            if (count > 0) {\n",
    "                totalTweets.getAndAdd(count)\n",
    "                totalChars.getAndAdd(rdd.reduce((x,y) => x + y))\n",
    "                println(\"Average length: \" + totalChars.get() / totalTweets.get())\n",
    "            }\n",
    "        })\n",
    "\n",
    "        // Blow out each word into a new DStream\n",
    "        val words = statuses.flatMap(tweetText => tweetText.split(\" \"))\n",
    "        // Now eliminate anything that's not a hashtag\n",
    "        val hashtags = words.filter(word => word.startsWith(\"#\"))\n",
    "        // Map each hashtag to a key/value pair of (hashtag, 1)\n",
    "        val hashtagKeyValues = hashtags.map(hashtag => (hashtag, 1))\n",
    "        // Now count them up over a 5 minute window sliding every 1 second\n",
    "        val hashtagCounts = hashtagKeyValues.reduceByKeyAndWindow(_ + _, _ - _, Seconds(300), Seconds(1))\n",
    "        // Sort the results by the count values\n",
    "        val result = hashtagCounts.transform(rdd => rdd.sortBy(x => x._2, false))\n",
    "        // Print the top 10\n",
    "        result.print\n",
    "\n",
    "        // Set a checkpoint directory, and kick it all off\n",
    "        ssc.checkpoint(\"/tmp/checkpoint/\")\n",
    "        ssc.start()\n",
    "        ssc.awaitTermination()\n",
    "    }\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala211",
   "nbconvert_exporter": "script",
   "pygments_lexer": "scala",
   "version": "2.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
