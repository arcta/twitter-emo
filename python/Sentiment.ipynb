{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "Mining tweet-stream sentiment real time could be challenging: tweets are short, multilingual, truncated/incomplete, contain abbreviations, symbols and emoji. Emojis could be very helpful, we can mine them separately and use as sentiment indicators on the stream.\n",
    "\n",
    "#### Emoji\n",
    "[Starter model using polar queries](EmojiSentiment.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "esent = {}\n",
    "with open('sentiment.txt','r') as source:\n",
    "    for line in source.readlines():\n",
    "        emoticon, sentiment = line.strip().split()\n",
    "        esent[emoticon] = float(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "sample  = 'Hola ğŸ˜‹ cÃ³mo estÃ¡s?'\n",
    "for char in sample:\n",
    "    if char in esent:\n",
    "        print(esent[char])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text\n",
    "Starter model using [TextBlob-NLTK](http://textblob.readthedocs.io/en/dev/_modules/textblob/en/sentiments.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!pip install textblob\n",
    "#!python -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['de', 'la', 'que', 'el', 'en', 'y', 'a', 'los', 'del', 'se']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "# >>>nltk.download('stopwords')\n",
    "\n",
    "nltk.corpus.stopwords.words('spanish')[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['au', 'aux', 'avec', 'ce', 'ces', 'dans', 'de', 'des', 'du', 'elle']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.stopwords.words('french')[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords = { word:1 for word in nltk.corpus.stopwords.words('english') }\n",
    "\n",
    "# for lang in ['danish', 'dutch', 'finnish', 'french', 'german', 'hungarian', 'italian',\n",
    "#             'norwegian', 'portuguese', 'russian', 'spanish', 'swedish', 'turkish']:\n",
    "#    for word in nltk.corpus.stopwords.words('spanish'): stopwords[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- in -------------------------------------------\n",
      "Words: ['awak', 'pernah', 'pakai', 'peeling', 'produk', 'bila', 'stop', 'muka', 'jadi', 'breakout', 'jom', 'detox', 'muka', 'awak', 'dengan', 'mary', 'kay', 'botani']\n",
      "Emoji: ['ğŸ‘‰']\n",
      "Hashtags: []\n",
      "Sentiment: 1.000\n",
      "ğŸ‘‰Awak pernah pakai peeling produk,  bila stop muka jadi breakout? Jom detox muka awak dengan MARY KAY,  100% botaniâ€¦ https://t.co/SFAoKGfMTt\n",
      "\n",
      "-- ja -------------------------------------------\n",
      "Words: ['æ°´é¤ƒå­ã‚‚å¤§å¥½ãã§ã™ã­']\n",
      "Emoji: ['ğŸ’—']\n",
      "Hashtags: []\n",
      "Sentiment: 1.000\n",
      "@sezuna1168 æ°´é¤ƒå­ã‚‚å¤§å¥½ãã§ã™ã­ğŸ’—\n",
      "\n",
      "-- und -------------------------------------------\n",
      "Words: []\n",
      "Emoji: ['â™€', '\\U0001f937']\n",
      "Hashtags: []\n",
      "Sentiment: 0.261\n",
      "@TanevinG ğŸ¤·ğŸ»â€â™€ï¸ğŸ¤·ğŸ»â€â™€ï¸ğŸ¤·ğŸ»â€â™€ï¸\n",
      "\n",
      "-- en -------------------------------------------\n",
      "Words: ['kingsmoovy', 'sorry', 'hear', 'man', 'condolences']\n",
      "Emoji: []\n",
      "Hashtags: []\n",
      "Sentiment: -0.500\n",
      "@Small @KingSmoovy Sorry to hear that man, My condolences.\n",
      "\n",
      "-- en -------------------------------------------\n",
      "Words: ['dream', 'team', 'happy', 'birthday', 'debbie', 'schroeder', 'goalsacademy', 'funny']\n",
      "Emoji: []\n",
      "Hashtags: ['#goalsacademy', '#funny']\n",
      "Sentiment: 0.525\n",
      "DREAM TEAM! Happy Birthday Debbie Schroeder! #goalsacademy #funnyâ€¦ https://t.co/wsmmqZ7tE0\n",
      "\n",
      "-- en -------------------------------------------\n",
      "Words: ['favorite', 'movie']\n",
      "Emoji: ['ğŸ˜']\n",
      "Hashtags: []\n",
      "Sentiment: 0.442\n",
      "My favorite movie ğŸ˜ https://t.co/ZCCB7k3P0B\n",
      "\n",
      "-- en -------------------------------------------\n",
      "Words: ['great', 'way', 'end', 'night']\n",
      "Emoji: []\n",
      "Hashtags: []\n",
      "Sentiment: 0.800\n",
      "what a great way to end the night: https://t.co/2iSaNVCnYY\n",
      "\n",
      "-- und -------------------------------------------\n",
      "Words: ['iainshipp', 'congrats', 'cali']\n",
      "Emoji: ['ğŸ˜Š']\n",
      "Hashtags: []\n",
      "Sentiment: 1.000\n",
      "@likeluversdo @IainShipp congrats Cali ğŸ˜Š\n",
      "\n",
      "-- es -------------------------------------------\n",
      "Words: ['hay', 'de', 'quÃ©']\n",
      "Emoji: ['ğŸ’š']\n",
      "Hashtags: []\n",
      "Sentiment: 1.000\n",
      "@lxst_memories_ no hay de quÃ©ğŸ’šğŸ’šğŸ’šğŸ’š\n",
      "\n",
      "-- el -------------------------------------------\n",
      "Words: ['titi', 'tito', 'ÎºÎ±Î»Î·Î¼ÎµÏÎ±', 'ÎºÎ±Î»Î·Î¼ÎµÏÎ±', 'Ï€Î±Î¹Î´Î¹Î±', 'ÎºÎ±Î»Î¿', 'Ïƒ', 'Îº']\n",
      "Emoji: ['ğŸŒ¹']\n",
      "Hashtags: []\n",
      "Sentiment: 1.000\n",
      "@trompoukikwn @titi55tito ÎºÎ±Î»Î·Î¼ÎµÏÎ± ÎºÎ±Î»Î·Î¼ÎµÏÎ± Ï€Î±Î¹Î´Î¹Î± ÎºÎ±Î»Î¿ Î£/Îš ğŸŒ¹\n",
      "\n",
      "-- en -------------------------------------------\n",
      "Words: ['get', 'back', 'sleep', 'could', 'gone', 'gym', 'nuffieldhealth', 'open', 'pm', 'weekends']\n",
      "Emoji: ['ğŸ˜ ']\n",
      "Hashtags: []\n",
      "Sentiment: -1.000\n",
      "Up at 515am and can't get back to sleep now. Could have just gone to the gym but @NuffieldHealth don't open until 8pm on the weekends. ğŸ˜ \n",
      "\n",
      "-- fr -------------------------------------------\n",
      "Words: ['un', 'gros', 'vous', 'elodiegossuin', 'pour', 'ce', 'soir', 'je', 'croie', 'fort', 'en', 'vous']\n",
      "Emoji: ['ğŸ’ª', 'â¤']\n",
      "Hashtags: []\n",
      "Sentiment: 0.665\n",
      "Un gros m**** a vous @Elodiegossuin pour ce soir je croie fort en vous ğŸ’ªğŸ¼ğŸ’ªğŸ¼â¤ï¸â¤ï¸â¤ï¸ https://t.co/qh4KnmNJuq\n",
      "\n",
      "-- pt -------------------------------------------\n",
      "Words: ['tu', 'sabe', 'que', 'Ã©', 'pra', 'tu', 'negaaaaaaaan']\n",
      "Emoji: ['ğŸ˜™']\n",
      "Hashtags: []\n",
      "Sentiment: 1.000\n",
      "Tu sabe que Ã© pra tu negaaaaaaaanğŸ˜™\n",
      "\n",
      "-- en -------------------------------------------\n",
      "Words: ['dumbest', 'tweet', 'day', 'goes']\n",
      "Emoji: ['ğŸ‘‡']\n",
      "Hashtags: []\n",
      "Sentiment: 0.255\n",
      "And the dumbest tweet of the day goes to ğŸ‘‡ğŸ‘‡ğŸ‘‡ https://t.co/XbmMzDjaqm\n",
      "\n",
      "-- en -------------------------------------------\n",
      "Words: ['wrong']\n",
      "Emoji: []\n",
      "Hashtags: []\n",
      "Sentiment: -0.500\n",
      "@dianneguurl What is wrong with you\n",
      "\n",
      "-- tl -------------------------------------------\n",
      "Words: ['yung', 'kanta', 'dito', 'sa', 'salon', 'nakakaiyak', 'lalo']\n",
      "Emoji: ['ğŸ˜­']\n",
      "Hashtags: []\n",
      "Sentiment: 0.646\n",
      "Yung kanta dito sa salon nakakaiyak laloğŸ˜­\n",
      "\n",
      "-- en -------------------------------------------\n",
      "Words: ['concert', 'grammy', 'golden', 'globe', 'award', 'winning', 'artist', 'kitaro', 'spectacular', 'live']\n",
      "Emoji: []\n",
      "Hashtags: []\n",
      "Sentiment: 0.384\n",
      "In concert; Grammy and Golden Globe Award-winning artist Kitaro in his Spectacular 2017 Live inâ€¦ https://t.co/jE4n3UClY0\n",
      "\n",
      "-- ar -------------------------------------------\n",
      "Words: ['Ø§Ù„Ù…Ø±Ø£Ø©', 'ØªØ­ØªØ§Ø¬', 'Ø¥Ù„Ù‰', 'ÙƒÙˆØ¨', 'Ù…ÙŠ', 'ÙÙŠ', 'Ø§Ù„Ù†Ù‡Ø§Ø±', 'Ø¨ÙŠÙ†Ù…Ø§', 'Ø§Ù„Ø±Ø§Ø¬Ù„', 'ÙŠØ­ØªØ§Ø¬', 'Ø¥Ù„Ù‰', 'ÙƒÙˆØ¨', 'ÙÙŠ', 'Ø§Ù„Ù†Ù‡Ø§Ø±', 'Ù…Ø¹Ù„ÙˆÙ…Ù‡', 'Ù…Ù‡Ù…Ù‡']\n",
      "Emoji: ['ğŸ‘']\n",
      "Hashtags: []\n",
      "Sentiment: 0.943\n",
      "Ø§Ù„Ù…Ø±Ø£Ø© ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ 12 ÙƒÙˆØ¨ Ù…ÙŠ ÙÙŠ Ø§Ù„Ù†Ù‡Ø§Ø± /Ø¨ÙŠÙ†Ù…Ø§ Ø§Ù„Ø±Ø§Ø¬Ù„ ÙŠØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ 13/14ÙƒÙˆØ¨ ÙÙŠ Ø§Ù„Ù†Ù‡Ø§Ø±/ Ù…Ø¹Ù„ÙˆÙ…Ù‡ Ù…Ù‡Ù…Ù‡ğŸ‘ https://t.co/ZONk5aI1nZ\n",
      "\n",
      "-- en -------------------------------------------\n",
      "Words: ['oh', 'godddddd']\n",
      "Emoji: ['ğŸ˜©']\n",
      "Hashtags: []\n",
      "Sentiment: 0.290\n",
      "OH MY GODDDDDD ğŸ˜©ğŸ˜© https://t.co/8B44HfybjO\n",
      "\n",
      "-- es -------------------------------------------\n",
      "Words: ['cuando', 'cumples', 'aÃ±os', 'dos', 'veces', 'al', 'aÃ±o', 'te', 'celebran', 'los', 'dos', 'dias', 'amigos', 'como', 'ellos', 'ningunos', 'ninguno', 'como', 'l']\n",
      "Emoji: ['ğŸ', 'ğŸ˜', '\\U0001f5a4', 'ğŸ‰']\n",
      "Hashtags: []\n",
      "Sentiment: 0.975\n",
      "Cuando cumples aÃ±os dos veces al aÃ±o y te celebran los dos dias ğŸ–¤ğŸ˜ğŸğŸ‰ amigos como ellos, ningunos!! Y ninguno como lâ€¦ https://t.co/owaiFrJtpH\n",
      "\n",
      "-- en -------------------------------------------\n",
      "Words: ['wants', 'get', 'married', 'wanna', 'marry']\n",
      "Emoji: ['ğŸ˜‚']\n",
      "Hashtags: []\n",
      "Sentiment: 0.470\n",
      "She wants to get married but I don't wanna marry her ğŸ˜‚\n",
      "\n",
      "-- en -------------------------------------------\n",
      "Words: ['wonderful', 'awakening', 'good', 'morning']\n",
      "Emoji: []\n",
      "Hashtags: []\n",
      "Sentiment: 0.850\n",
      "@MahaSelem1 Wonderful awakening and good morning! https://t.co/CUiG91YrOD\n",
      "\n",
      "-- en -------------------------------------------\n",
      "Words: ['magic', 'u', 'demarkisj', 'schulzyy', 'yes', 'sir', 'cant', 'say', 'go', 'good', 'luck', 'hope', 'yall', 'well', 'th']\n",
      "Emoji: []\n",
      "Hashtags: []\n",
      "Sentiment: 0.600\n",
      "@Zhaglan @Magic16U @demarkisj_ @Schulzyy12 Yes Sir! I CANT say Go ..... but Good luck and hope yall do well over thâ€¦ https://t.co/KGSJV0eJPW\n",
      "\n",
      "-- en -------------------------------------------\n",
      "Words: ['climb', 'ladder', 'success', 'hands', 'pockets', 'aldubtuwingkasamaka']\n",
      "Emoji: []\n",
      "Hashtags: ['#ALDUBTuwingKasamaKa']\n",
      "Sentiment: 0.300\n",
      "You can't climb the ladder of success with your hands in your pockets\n",
      "#ALDUBTuwingKasamaKa\n",
      "\n",
      "-- en -------------------------------------------\n",
      "Words: ['heineken', 'sa', 'djnaves', 'aewonwolf', 'opening', 'nrb', 'fam']\n",
      "Emoji: ['ğŸ¤”']\n",
      "Hashtags: []\n",
      "Sentiment: 0.879\n",
      "@SPHEctacula @Heineken_SA @DJNAVES @AewonWolf When are y'all opening NRB fam?ğŸ¤”\n",
      "\n",
      "-- ja -------------------------------------------\n",
      "Words: ['ã‚„ã£ãŸãœ', 'ã“ã‚Œã•ã£ãçµ‚ã‚ã£ãŸå¾Œã®ä¸€ç™ºç›®ãªã‚“ã™']\n",
      "Emoji: ['ğŸ¤”']\n",
      "Hashtags: []\n",
      "Sentiment: 0.879\n",
      "@mochico_f ã‚„ã£ãŸãœï¼ã“ã‚Œã•ã£ãçµ‚ã‚ã£ãŸå¾Œã®ä¸€ç™ºç›®ãªã‚“ã™â€¦ğŸ¤”\n",
      "\n",
      "-- en -------------------------------------------\n",
      "Words: ['love', 'peace', 'kids', 'love', 'peace']\n",
      "Emoji: []\n",
      "Hashtags: []\n",
      "Sentiment: 0.500\n",
      "Love and peace kids. Love and peace.\n",
      "\n",
      "-- ar -------------------------------------------\n",
      "Words: ['adelalibinali', 'ØªØ´ÙˆÙ', 'ÙŠØ§Ø¨Ùˆ', 'Ø¹Ø²ÙˆØ²']\n",
      "Emoji: ['ğŸ˜‚']\n",
      "Hashtags: []\n",
      "Sentiment: 0.715\n",
      "@apoazoo @AdelAliBinAli ØªØ´ÙˆÙ ÙŠØ§Ø¨Ùˆ Ø¹Ø²ÙˆØ²ğŸ˜‚\n",
      "\n",
      "-- es -------------------------------------------\n",
      "Words: ['hoy', 'fue', 'un', 'dÃ­a', 'con', 'suerte', 'espero', 'todas', 'las', 'fuerzas', 'cÃ³smicas', 'sobrenaturales', 'se', 'alineen', 'maÃ±ana', 'tambiÃ©n']\n",
      "Emoji: ['\\U0001f91e', 'ğŸ¤—', 'ğŸ™', 'ğŸ˜']\n",
      "Hashtags: []\n",
      "Sentiment: 0.947\n",
      "Hoy fue un dÃ­a con suerte. Espero y todas las fuerzas cÃ³smicas y sobrenaturales se alineen maÃ±ana tambiÃ©n. ğŸ¤—ğŸ˜ğŸ™ğŸ¼ğŸ¤ğŸ»\n",
      "\n",
      "-- en -------------------------------------------\n",
      "Words: ['excellent', 'firebomber', 'thanks', 'miss', 'kayla']\n",
      "Emoji: []\n",
      "Hashtags: []\n",
      "Sentiment: 0.600\n",
      "@KaylaKleevage excellent firebomber, thanks miss kayla\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import sys\n",
    "import json\n",
    "from textblob import TextBlob\n",
    "from collections import Counter\n",
    "from client import TwitterClient\n",
    "\n",
    "def score(e, count):\n",
    "    if count == 1 or abs(esent[e]) == 1: return esent[e]\n",
    "    # scale up the signal for repeated emoticon\n",
    "    s = abs(esent[e]) ** 1/count\n",
    "    if esent[e] < 0: return - s\n",
    "    return s\n",
    "\n",
    "\n",
    "def extract(data):\n",
    "    try:\n",
    "        obj = json.loads(data)\n",
    "        if 'text' in obj:\n",
    "            # extract hashtags\n",
    "            hashtags = ['#{}'.format(re.sub('\\W+', '', term)) for term in obj['text'].split() if term[0] == '#']\n",
    "            # extract emoji\n",
    "            emo = Counter([c for c in obj['text'] if c in esent])\n",
    "            polarity = 0.\n",
    "            # remove links and all non-letter chacracters\n",
    "            words = re.sub('(@\\S+)|(https?\\://\\S+)|([\\W\\d_]+)', ' ', obj['text'].lower()).split()\n",
    "            # remove stopwords\n",
    "            words = [word for word in words if word not in stopwords]\n",
    "            if obj['lang'] == 'en':\n",
    "                # calculate sentiment score\n",
    "                polarity = TextBlob(' '.join(words)).sentiment.polarity\n",
    "            if len(emo) > 0:\n",
    "                # get emoji sentiment scores\n",
    "                sentiment = [score(e, c) for e, c in emo.items() if esent[e] != 0]\n",
    "                # calculate tweet sentiment score as average of text and emoji scores\n",
    "                if polarity != 0:\n",
    "                    sentiment.append(polarity)\n",
    "                if len(sentiment) > 0:\n",
    "                    polarity = sum(sentiment)/len(sentiment)\n",
    "            if polarity > 0.25 or polarity < -0.25:\n",
    "                print('\\n-- {} -------------------------------------------'.format(obj['lang']))\n",
    "                print('Words: {}'.format(words))\n",
    "                print('Emoji: {}'.format(list(emo.keys())))\n",
    "                print('Hashtags: {}'.format(hashtags))\n",
    "                print('Sentiment: {:.3f}'.format(polarity))\n",
    "                print(obj['text'])\n",
    "    except:\n",
    "        print('------------------------------------------------------------------------')\n",
    "        print('Error: {}'.format(sys.exc_info()))\n",
    "\n",
    "twitter = TwitterClient()\n",
    "twitter.stream('', geo = True, broadcast = extract, count = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
